---
title: hand_writting
description: docker log
weight: 300
---
```python
# å°å…¥å‡½å¼åº«
import numpy as np  
from keras.models import Sequential
from keras.datasets import mnist
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.utils import to_categorical #np_utils  # ç”¨ä¾†å¾ŒçºŒå°‡ label æ¨™ç±¤è½‰ç‚º one-hot-encoding  
from matplotlib import pyplot as plt

# è¼‰å…¥ MNIST è³‡æ–™åº«çš„è¨“ç·´è³‡æ–™ï¼Œä¸¦è‡ªå‹•åˆ†ç‚ºã€è¨“ç·´çµ„ã€åŠã€æ¸¬è©¦çµ„ã€
(X_train, y_train), (X_test, y_test) = mnist.load_data()


# å»ºç«‹ç°¡å–®çš„ç·šæ€§åŸ·è¡Œçš„æ¨¡å‹
model = Sequential()
# Add Input layer, éš±è—å±¤(hidden layer) æœ‰ 256å€‹è¼¸å‡ºè®Šæ•¸
model.add(Dense(units=256, input_dim=784, kernel_initializer='normal', activation='relu')) 
# Add output layer
model.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))

# ç·¨è­¯: é¸æ“‡æå¤±å‡½æ•¸ã€å„ªåŒ–æ–¹æ³•åŠæˆæ•ˆè¡¡é‡æ–¹å¼
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) 

# å°‡ training çš„ label é€²è¡Œ one-hot encodingï¼Œä¾‹å¦‚æ•¸å­— 7 ç¶“é One-hot encoding è½‰æ›å¾Œæ˜¯ 0000001000ï¼Œå³ç¬¬7å€‹å€¼ç‚º 1
y_TrainOneHot = to_categorical(y_train) 
y_TestOneHot = to_categorical(y_test) 

# å°‡ training çš„ input è³‡æ–™è½‰ç‚º2ç¶­
X_train_2D = X_train.reshape(60000, 28*28).astype('float32')  
X_test_2D = X_test.reshape(10000, 28*28).astype('float32')  

x_Train_norm = X_train_2D/255
x_Test_norm = X_test_2D/255

# é€²è¡Œè¨“ç·´, è¨“ç·´éç¨‹æœƒå­˜åœ¨ train_history è®Šæ•¸ä¸­
train_history = model.fit(x=x_Train_norm, y=y_TrainOneHot, validation_split=0.2, epochs=1, batch_size=800, verbose=2)  

# é¡¯ç¤ºè¨“ç·´æˆæœ(åˆ†æ•¸)
scores = model.evaluate(x_Test_norm, y_TestOneHot)  
print()  
print("\t[Info] Accuracy of testing data = {:2.1f}%".format(scores[1]*100.0))  

# é æ¸¬(prediction)
X = x_Test_norm[0:10,:]
predictions = np.argmax(model.predict(X), axis=-1)
# get prediction result
print(predictions)
```

    c:\Users\linchao\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
      super().__init__(activity_regularizer=activity_regularizer, **kwargs)
    

    60/60 - 2s - 38ms/step - accuracy: 0.8174 - loss: 0.7601 - val_accuracy: 0.9121 - val_loss: 0.3199
    [1m313/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step - accuracy: 0.8934 - loss: 0.3773
    
    	[Info] Accuracy of testing data = 91.0%
    [1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 190ms/step
    [7 2 1 0 4 1 4 9 6 9]
    

é¡¯ç¤º ç¬¬ä¸€ç­†è¨“ç·´è³‡æ–™çš„åœ–å½¢ï¼Œç¢ºèªæ˜¯å¦æ­£ç¢º


```python
plt.imshow(X_test[0])
plt.show() 
```


    
![png](output_2_0.png)
    



```python
plt.plot(train_history.history['loss'])  
plt.plot(train_history.history['val_loss'])  
plt.title('Train History')  
plt.ylabel('loss')  
plt.xlabel('Epoch')  
plt.legend(['loss', 'val_loss'], loc='upper left')  
plt.show() 
```


    
![png](output_3_0.png)
    


Activation Functionæœ‰å¾ˆå¤šç¨®ï¼Œå¯ä¾æ“šå•é¡Œçš„æœ¬è³ªï¼ŒæŒ‘é¸é©åˆçš„å‡½æ•¸è¨“ç·´æ¨¡å‹ï¼Œè«‹åƒé–±ä¸‹åœ–ï¼ŒSigmoid å‡½æ•¸å°±èƒ½ä½¿Yçš„ç¯„åœé™åˆ¶åœ¨[0,1]ä¹‹é–“ï¼Œä¸­é–“åªæœ‰ä¸€å°æ®µæ¨¡ç³Šåœ°å¸¶ï¼Œé©åˆç”¨æ–¼äºŒåˆ†æ³•(çœŸæˆ–å½)ï¼Œå¦å¤– softmax å‡½æ•¸ï¼Œå¯ä»¥å°‡Yè½‰ç‚ºæ©Ÿç‡å€¼ï¼Œä¸”æ‰€æœ‰é¡åˆ¥çš„æ©Ÿç‡ç¸½å’Œç­‰æ–¼1ï¼Œå°±é©åˆå¤šåˆ†é¡ï¼Œæœ€å¤§å€¼å°±ä»£è¡¨å¯èƒ½æ€§æœ€å¤§ï¼›ä¸Šæ¬¡é‚„æœ‰ç”¨åˆ° reluå‡½æ•¸ï¼Œå®ƒæ˜¯å¿½è¦–è² å€¼ï¼ŒYçš„ç¯„åœé™åˆ¶åœ¨[0, âˆ]ä¹‹é–“ï¼Œé‚„æœ‰å…¶ä»–å‡½æ•¸ï¼Œå°±æ˜¯ä¾ç…§è³‡æ–™åŠæ¨¡å‹çš„ç‰¹æ€§æŒ‘é¸å°±å°äº†
![](../resource/hand_writting_1.png)


```python
import keras
dot_img_file = '../resource/model_1.png'
keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)
```




    
![png](output_5_0.png)
    


