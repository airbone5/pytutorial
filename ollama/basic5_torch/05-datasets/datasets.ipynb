{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pywork\\ollama\\basic5_torch\\prj\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets 基本使用"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加載在線數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 5850\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 1679\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = load_dataset(\"madao33/new-title-chinese\")\n",
    "datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加載數據集合集中的某一項任務"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|▓▓▓▓▓▓▓▓▓▓| 4.12M/4.12M [00:00<00:00, 12.6MB/s]\n",
      "Generating train split: 100%|▓▓▓▓▓▓▓▓▓▓| 9427/9427 [00:00<00:00, 61328.01 examples/s]\n",
      "Generating validation split: 100%|▓▓▓▓▓▓▓▓▓▓| 3270/3270 [00:00<00:00, 65644.22 examples/s]\n",
      "Generating test split: 100%|▓▓▓▓▓▓▓▓▓▓| 3245/3245 [00:00<00:00, 53730.04 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 9427\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 3270\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 3245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolq_dataset = load_dataset(\"super_glue\", \"boolq\",trust_remote_code=True)\n",
    "boolq_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照數據集劃分進行加載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content'],\n",
       "    num_rows: 5850\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"madao33/new-title-chinese\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content'],\n",
       "    num_rows: 90\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"madao33/new-title-chinese\", split=\"train[10:100]\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content'],\n",
       "    num_rows: 2925\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"madao33/new-title-chinese\", split=\"train[:50%]\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['title', 'content'],\n",
       "     num_rows: 2925\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['title', 'content'],\n",
       "     num_rows: 2925\n",
       " })]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"madao33/new-title-chinese\", split=[\"train[:50%]\", \"train[50%:]\"])\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 5850\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 1679\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = load_dataset(\"madao33/new-title-chinese\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '望海樓美國打「台灣牌」是危險的賭博',\n",
       " 'content': '近期，美國國會眾院通過法案，重申美國對台灣的承諾。對此，中國外交部發言人表示，有關法案嚴重違反一個中國原則和中美三個聯合公報規定，粗暴干涉中國內政，中方對此堅決反對並已向美方提出嚴正交涉。\\n事實上，中國高度關注美國國內打「台灣牌」、挑戰一中原則的危險動向。近年來，作為「親台」勢力大本營的美國國會動作不斷，先後通過「與台灣交往法」「亞洲再保證倡議法」等一系列「挺台」法案，「2019財年國防授權法案」也多處觸及台灣問題。今年3月，美參院親台議員再拋「台灣保證法」草案。眾院議員繼而在4月提出眾院版的草案並在近期通過。上述法案的核心目標是強化美台關係，並將台作為美「印太戰略」的重要夥伴。同時，「親台」議員還有意製造事端。今年2月，5名共和黨參議員致信眾議院議長，促其邀請台灣地區領導人在國會上發表講話。這一動議顯然有悖於美國與台灣的非官方關係，其用心是實質性改變美台關係定位。\\n上述動向出現並非偶然。在中美建交40週年之際，兩國關係摩擦加劇，所謂「中國威脅論」再次沉渣泛起。美國對華認知出現嚴重偏差，對華政策中負面因素上升，保守人士甚至成立了「當前中國威脅委員會」。在此背景下，美國將台海關係作為戰略抓手，通過打「台灣牌」在雙邊關係中增加籌碼。特朗普就任後，國會對總統外交政策的約束力和塑造力加強。其實國會推動通過涉台法案對行政部門不具約束力，美政府在2018年並未提升美台官員互訪級別，美軍艦也沒有「訪問」台灣港口，保持著某種克制。但從美總統簽署國會通過的法案可以看出，國會對外交產生了影響。立法也為政府對台政策提供更大空間。\\n然而，美國需要認真衡量打「台灣牌」成本。首先是美國應對危機的代價。美方官員和學者已明確發出警告，美國捲入台灣問題得不償失。美國學者曾在媒體發文指出，如果台海爆發危機，美國可能需要「援助」台灣，進而導致新的冷戰乃至與中國大陸的衝突。但如果美國讓台灣自己面對，則有損美國的信譽，影響美盟友對同盟關係的支持。其次是對中美關係的危害。歷史證明，中美合則兩利、斗則兩傷。中美關係是當今世界最重要的雙邊關係之一，保持中美關係的穩定發展，不僅符合兩國和兩國人民的根本利益，也是國際社會的普遍期待。美國蓄意挑戰台灣問題的底線，加劇中美關係的複雜性和不確定性，損害兩國在重要領域合作，損人又害己。\\n美國打「台灣牌」是一場危險的賭博。台灣問題是中國核心利益，中國政府和人民決不會對此坐視不理。中國敦促美方恪守一個中國原則和中美三個聯合公報規定，阻止美國會審議推進有關法案，妥善處理涉台問題。美國懸崖勒馬，才是明智之舉。\\n（作者系中國國際問題研究院國際戰略研究所副所長）'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ['望海樓美國打「台灣牌」是危險的賭博', '大力推進高校治理能力建設'],\n",
       " 'content': ['近期，美國國會眾院通過法案，重申美國對台灣的承諾。對此，中國外交部發言人表示，有關法案嚴重違反一個中國原則和中美三個聯合公報規定，粗暴干涉中國內政，中方對此堅決反對並已向美方提出嚴正交涉。\\n事實上，中國高度關注美國國內打「台灣牌」、挑戰一中原則的危險動向。近年來，作為「親台」勢力大本營的美國國會動作不斷，先後通過「與台灣交往法」「亞洲再保證倡議法」等一系列「挺台」法案，「2019財年國防授權法案」也多處觸及台灣問題。今年3月，美參院親台議員再拋「台灣保證法」草案。眾院議員繼而在4月提出眾院版的草案並在近期通過。上述法案的核心目標是強化美台關係，並將台作為美「印太戰略」的重要夥伴。同時，「親台」議員還有意製造事端。今年2月，5名共和黨參議員致信眾議院議長，促其邀請台灣地區領導人在國會上發表講話。這一動議顯然有悖於美國與台灣的非官方關係，其用心是實質性改變美台關係定位。\\n上述動向出現並非偶然。在中美建交40週年之際，兩國關係摩擦加劇，所謂「中國威脅論」再次沉渣泛起。美國對華認知出現嚴重偏差，對華政策中負面因素上升，保守人士甚至成立了「當前中國威脅委員會」。在此背景下，美國將台海關係作為戰略抓手，通過打「台灣牌」在雙邊關係中增加籌碼。特朗普就任後，國會對總統外交政策的約束力和塑造力加強。其實國會推動通過涉台法案對行政部門不具約束力，美政府在2018年並未提升美台官員互訪級別，美軍艦也沒有「訪問」台灣港口，保持著某種克制。但從美總統簽署國會通過的法案可以看出，國會對外交產生了影響。立法也為政府對台政策提供更大空間。\\n然而，美國需要認真衡量打「台灣牌」成本。首先是美國應對危機的代價。美方官員和學者已明確發出警告，美國捲入台灣問題得不償失。美國學者曾在媒體發文指出，如果台海爆發危機，美國可能需要「援助」台灣，進而導致新的冷戰乃至與中國大陸的衝突。但如果美國讓台灣自己面對，則有損美國的信譽，影響美盟友對同盟關係的支持。其次是對中美關係的危害。歷史證明，中美合則兩利、斗則兩傷。中美關係是當今世界最重要的雙邊關係之一，保持中美關係的穩定發展，不僅符合兩國和兩國人民的根本利益，也是國際社會的普遍期待。美國蓄意挑戰台灣問題的底線，加劇中美關係的複雜性和不確定性，損害兩國在重要領域合作，損人又害己。\\n美國打「台灣牌」是一場危險的賭博。台灣問題是中國核心利益，中國政府和人民決不會對此坐視不理。中國敦促美方恪守一個中國原則和中美三個聯合公報規定，阻止美國會審議推進有關法案，妥善處理涉台問題。美國懸崖勒馬，才是明智之舉。\\n（作者系中國國際問題研究院國際戰略研究所副所長）',\n",
       "  '在推進「雙一流」高校建設進程中，我們要緊緊圍繞為黨育人、為國育才，找準問題、破解難題，以一流意識和擔當精神，大力推進高校的治理能力建設。\\n增強政治引領力。堅持黨對高校工作的全面領導，始終把政治建設擺在首位，增強校黨委的政治領導力，全面推進黨的建設各項工作。落實立德樹人根本任務，把培養社會主義建設者和接班人放在中心位置。緊緊抓住思想政治工作這條生命線，全面加強師生思想政治工作，推進「三全育人」綜合改革，將思想政治工作貫穿學校教育管理服務全過程，努力讓學生成為德才兼備、全面發展的人才。\\n提升人才聚集力。人才是創新的核心要素，創新驅動本質上是人才驅動。要堅持引育並舉，建立綠色通道，探索知名專家舉薦制，完善「一事一議」支持機制。在大力支持自然科學人才隊伍建設的同時，實施哲學社會科學人才工程。立足實際，在條件成熟的學院探索「一院一策」改革。創新科研組織形式，為人才成長創設空間，建設更加崇尚學術、更加追求卓越、更加關愛學生、更加擔當有為的學術共同體。\\n培養學生競爭力。遵循學生成長成才的規律培育人才，著力培養具有國際競爭力的拔尖創新人才和各類專門人才，使優勢學科、優秀教師、優質資源、優良環境圍繞立德樹人的根本任務配置。淘汰「水課」，打造「金課」，全力打造世界一流本科教育。深入推進研究生教育綜合改革，加強事關國家重大戰略的高精尖急缺人才培養，建設具有國際競爭力的研究生教育。\\n激發科技創新力。在國家急需發展的領域挑大樑，就要更加聚焦科技前沿和國家需求，狠抓平台建設，包括加快牽頭「武漢光源」建設步伐，積極參與國家實驗室建設，建立校級大型科研儀器設備共享平台。關鍵核心技術領域「卡脖子」問題，歸根結底是基礎科學研究薄弱。要加大基礎研究的支持力度，推進理論、技術和方法創新，鼓勵支持重大原創和顛覆性技術創新，催生一批高水平、原創性研究成果。\\n發展社會服務力。在貢獻和服務中體現價值，推動合作共建、多元投入的格局，大力推進政產學研用結合，強化科技成果轉移轉化及產業化。探索校城融合發展、校地聯動發展的新模式，深度融入地方創新發展網絡，為地方經濟社會發展提供人才支撐，不斷拓展和優化社會服務網絡。\\n涵育文化軟實力。加快體制機制改革，優化學校、學部、學院三級評審機制，充分發揮優秀學者特別是德才兼備的年輕學者在學術治理中的重要作用。牢固樹立一流意識、緊緊圍繞一流目標、認真執行一流標準，讓成就一流事業成為普遍追求和行動自覺。培育具有強大凝聚力的大學文化，營造積極團結、向上向善、幹事創業的氛圍，讓大學成為吸引和留住一大批優秀人才建功立業的沃土，讓敢幹事、肯幹事、能幹事的人有更多的榮譽感和獲得感。\\n建設中國特色、世界一流大學不是等得來、喊得來的，而是腳踏實地拼出來、幹出來的。對標一流，深化改革，堅持按章程辦學，構建以一流質量標準為核心的制度規範體系，紮實推進學校綜合改革，探索更具活力、更富效率的管理體制和運行機制，我們就一定能構建起具有中國特色的現代大學治理體系，進一步提升管理服務水平和工作效能。\\n（作者系武漢大學校長）']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['望海樓美國打「台灣牌」是危險的賭博',\n",
       " '大力推進高校治理能力建設',\n",
       " '堅持事業為上選賢任能',\n",
       " '「大朋友」的話兒記心頭',\n",
       " '用好可持續發展這把「金鑰匙」']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][\"title\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"train\"].features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數據集劃分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[\"train\"]\n",
    "dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = boolq_dataset[\"train\"]\n",
    "dataset.train_test_split(test_size=0.1, stratify_by_column=\"label\")     # 分類數據集可以按照比例劃分"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數據選取與過濾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選取\n",
    "datasets[\"train\"].select([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 過濾\n",
    "filter_dataset = datasets[\"train\"].filter(lambda example: \"中國\" in example[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dataset[\"title\"][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數據映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(example):\n",
    "    example[\"title\"] = 'Prefix: ' + example[\"title\"]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dataset = datasets.map(add_prefix)\n",
    "prefix_dataset[\"train\"][:10][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "def preprocess_function(example, tokenizer=tokenizer):\n",
    "    model_inputs = tokenizer(example[\"content\"], max_length=512, truncation=True)\n",
    "    labels = tokenizer(example[\"title\"], max_length=32, truncation=True)\n",
    "    # label就是title編碼的結果\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = datasets.map(preprocess_function)\n",
    "processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = datasets.map(preprocess_function, num_proc=4)\n",
    "processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = datasets.map(preprocess_function, batched=True)\n",
    "processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = datasets.map(preprocess_function, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "processed_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存與加載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets.save_to_disk(\"./processed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = load_from_disk(\"./processed_data\")\n",
    "processed_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加載本地數據集"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接加載文件作為數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"./ChnSentiCorp_htl_all.csv\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_csv(\"./ChnSentiCorp_htl_all.csv\")\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加載文件夾內全部文件作為數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=[\"./all_data/ChnSentiCorp_htl_all.csv\", \"./all_data/ChnSentiCorp_htl_all copy.csv\"], split='train')\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通過預先加載的其他格式轉換加載數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./ChnSentiCorp_htl_all.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List格式的數據需要內嵌{}，明確數據字段\n",
    "data = [{\"text\": \"abc\"}, {\"text\": \"def\"}]\n",
    "# data = [\"abc\", \"def\"]\n",
    "Dataset.from_list(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通過自定義加載腳本加載數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset(\"json\", data_files=\"./cmrc2018_trial.json\", field=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"./load_script.py\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset with DataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"./ChnSentiCorp_htl_all.csv\", split='train')\n",
    "dataset = dataset.filter(lambda x: x[\"review\"] is not None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_function(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"review\"], max_length=128, truncation=True)\n",
    "    tokenized_examples[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(process_function, batched=True, remove_columns=dataset.column_names)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_dataset[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(tokenized_dataset, batch_size=4, collate_fn=collator, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for batch in dl:\n",
    "    print(batch[\"input_ids\"].size())\n",
    "    num += 1\n",
    "    if num > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
